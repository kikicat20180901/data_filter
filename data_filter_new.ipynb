{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc941e4-a113-4ca4-a7fc-d680260562aa",
   "metadata": {},
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:100%;text-align:left;display:fill;border-radius:5px;background-color:#6A79BA;overflow:hidden\">Data Filter</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3757a8-560c-4d95-bcee-0131a6e2c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mmcao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/mmcao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df0=pd.read_csv('result/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6908fe-dc08-48b7-9e20-d167b68d0612",
   "metadata": {},
   "source": [
    "## Delete samples with too short titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5785ecd-46af-4ce6-a639-fa394d539aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()\n",
    "# filter out short news with too short title\n",
    "word_num_thres = 6\n",
    "df = df[df['title'].apply(lambda x: len(x.split()) >= word_num_thres)]\n",
    "\n",
    "# delete stopwords\n",
    "# df['title'] = df['title'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "# Calculate the deleted results by keywords\n",
    "df_deleted_by_too_short_titles = df0[~df0.index.isin(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e1a3b3-437d-4e78-936a-6badb85cbed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sym</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>56:48.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>U.S. FX Markets Open-January 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date timestamp  sym                           title\n",
       "13  1/2/2024   56:48.0  GBP  U.S. FX Markets Open-January 2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted_by_too_short_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc4f7e-c097-4164-9bd2-a23f95e75f89",
   "metadata": {},
   "source": [
    "## Method 1： Keywords-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f19a0d-4650-436c-88f4-88d0339ac688",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['GBP/USD', 'forex', 'stocks', 'economy', 'GBP', 'fed', 'USD', 'british', 'sterling', 'euro', 'UST yields', 'dollar', \n",
    "            'inflation', 'U.S. yields', 'EUR', 'pound', 'exchange rate']  # 定义关键词列表\n",
    "\n",
    "# filtered_df_kw = df[df['title'].apply(lambda x: (any(keyword.lower() in x.lower() for keyword in keywords) or any(re.search(r'\\b' + re.escape(keyword.lower()) + r'\\b', x.lower()) for keyword in keywords)))]\n",
    "filtered_df_kw = df[df['title'].str.contains('|'.join(keywords), case=False)] \n",
    "# Calculate the deleted results by keywords\n",
    "df_deleted_by_kw = df[~df.index.isin(filtered_df_kw.index)]\n",
    "\n",
    "# Output deleted and filtered DataFrame\n",
    "filtered_df_kw.to_csv('result/filtered_df_kw.csv', index=False)\n",
    "filtered_df_kw.to_excel('result/filtered_df_kw.xlsx', index=False)\n",
    "df_deleted_by_kw.to_csv('result/df_deleted_by_kw.csv', index=False)\n",
    "df_deleted_by_kw.to_excel('result/df_deleted_by_kw.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e7dc40-dae9-4b56-92b2-b18fcf09b747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sym</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2024</td>\n",
       "      <td>33:57.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-Asia Day Ahead-Focus on Xi comments and busy data schedule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>56:27.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-U.S. FX Markets Open- January 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>REG-VinaCapital Vietnam- Daily Net Asset Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>14:32.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-Larger option expiries for Tuesday's New York cut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date timestamp  sym  \\\n",
       "0   1/1/2024   33:57.0  GBP   \n",
       "12  1/2/2024   56:27.0  GBP   \n",
       "15  1/2/2024   00:00.0  GBP   \n",
       "20  1/2/2024   14:32.0  GBP   \n",
       "\n",
       "                                                              title  \n",
       "0   BUZZ-Asia Day Ahead-Focus on Xi comments and busy data schedule  \n",
       "12                             BUZZ-U.S. FX Markets Open- January 2  \n",
       "15                   REG-VinaCapital Vietnam- Daily Net Asset Value  \n",
       "20           BUZZ-Larger option expiries for Tuesday's New York cut  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted_by_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da42ae-8a14-4ca0-beb7-f96db189236d",
   "metadata": {},
   "source": [
    "# Method 2: TF-IDF feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6eb284-36cb-460a-b308-54c86c5180a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['title'])\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Calculate the average TF-IDF value for each sample\n",
    "average_tfidf_values = tfidf_matrix.mean(axis=1).flatten()\n",
    "average_tfidf_values = average_tfidf_values.A1.tolist()\n",
    "\n",
    "# Calculate the number of samples to delete based on the delete_ratio\n",
    "delete_ratio = 0.1  # 10% delete ratio\n",
    "num_samples_to_delete = int(delete_ratio * len(df))\n",
    "\n",
    "# Sort the average TF-IDF values in descending order\n",
    "sorted_tfidf_values = np.sort(average_tfidf_values)\n",
    "\n",
    "# Calculate the new threshold based on the delete_ratio\n",
    "new_threshold = sorted_tfidf_values[num_samples_to_delete]\n",
    "\n",
    "# Filter data based on the threshold\n",
    "filtered_indices = [idx for idx, val in enumerate(average_tfidf_values) if val >= new_threshold]\n",
    "filtered_df_tfidf = df.iloc[filtered_indices]\n",
    "\n",
    "# Calculate the deleted results by TF-IDF\n",
    "df_deleted_by_tfidf = df[~df.index.isin(filtered_df_tfidf.index)]\n",
    "\n",
    "# Output filtered DataFrame\n",
    "filtered_df_tfidf.to_csv('result/filtered_df_tfidf.csv', index=False)\n",
    "filtered_df_tfidf.to_excel('result/filtered_df_tfidf.xlsx', index=False)\n",
    "df_deleted_by_tfidf.to_csv('result/df_deleted_by_tfidf.csv', index=False)\n",
    "df_deleted_by_tfidf.to_excel('result/df_deleted_by_tfidf.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88f2d0e-b8a9-43d3-8a33-ce16e39669ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sym</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>09:25.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-COMMENT-Will investors vote for sterling this year?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>56:27.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-U.S. FX Markets Open- January 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date timestamp  sym  \\\n",
       "10  1/2/2024   09:25.0  GBP   \n",
       "12  1/2/2024   56:27.0  GBP   \n",
       "\n",
       "                                                       title  \n",
       "10  BUZZ-COMMENT-Will investors vote for sterling this year?  \n",
       "12                      BUZZ-U.S. FX Markets Open- January 2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted_by_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b82b91-73f0-4d48-bd7d-26789134f56f",
   "metadata": {},
   "source": [
    "## Method 3: LDA topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0d4532-c761-4dd9-97d5-df69d71d85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mmcao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "usd dollar buzz forex starts2024\n",
      "Topic 1:\n",
      "buzz forex starts2024 dollar usd\n",
      "Topic 2:\n",
      "buzz usd gbp 27 ust\n",
      "Topic 3:\n",
      "buzz eur gbp clouding versus\n",
      "Topic 4:\n",
      "buzz focus data yields sterling\n",
      "Topic 5:\n",
      "new option larger expiries tuesday\n",
      "Topic 6:\n",
      "dollar year buzz new york\n",
      "Topic 7:\n",
      "forex starts2024 bid yen gains\n",
      "Topic 8:\n",
      "buzz markets open january fx\n",
      "Topic 9:\n",
      "year sterling vote buzz comment\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Assuming df is your DataFrame containing the 'title' column\n",
    "titles = df['title'].tolist()\n",
    "\n",
    "# Preprocess the text\n",
    "vectorizer = CountVectorizer(stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(titles)\n",
    "\n",
    "# Set the number of topics\n",
    "n_topics = 10\n",
    "\n",
    "# Train the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the top 5 keywords for each topic\n",
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {i}:\")\n",
    "    print(\" \".join([vocab[i] for i in topic.argsort()[:-6:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef588db-3aec-460d-b256-6127fff66a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually select the topics to exclude (assuming we want to exclude topics 0 and 3)\n",
    "exclude_topics = [5, 7]\n",
    "\n",
    "# Get the topic distribution for each title\n",
    "topic_distribution = lda.transform(X)\n",
    "\n",
    "# Retain samples that do not belong to the excluded topics\n",
    "mask = ~np.isin(topic_distribution.argmax(axis=1), exclude_topics)\n",
    "filtered_df_lda = df[mask]\n",
    "df_deleted_by_lda = df[~mask]\n",
    "\n",
    "# Calculate the deleted results by LDA\n",
    "df_deleted_by_lda = df[~df.index.isin(filtered_df_lda.index)]\n",
    "\n",
    "filtered_df_lda.to_csv('result/filtered_df_lda.csv', index=False)\n",
    "filtered_df_lda.to_excel('result/filtered_df_lda.xlsx', index=False)\n",
    "df_deleted_by_lda.to_csv('result/df_deleted_by_lda.csv', index=False)\n",
    "df_deleted_by_lda.to_excel('result/df_deleted_by_lda.xlsx', index=False)\n",
    "columns=['date', 'timestamp', 'sym', 'title']\n",
    "filtered_df_lda = filtered_df_lda[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ada75e-09e9-4eba-8ae8-624dd169b6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sym</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>ANALYSIS-Sterling runs into economic and election hurdles after stellar year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>43:34.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-GBP/USD tentatively bid but signals are mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>06:38.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>FOREX-Dollar starts2024 with gains on yen and euro, bitcoin above $45,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>00:00.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>REG-VinaCapital Vietnam- Daily Net Asset Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>14:32.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>BUZZ-Larger option expiries for Tuesday's New York cut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date timestamp  sym  \\\n",
       "4   1/2/2024   00:00.0  GBP   \n",
       "6   1/2/2024   43:34.0  GBP   \n",
       "9   1/2/2024   06:38.0  GBP   \n",
       "15  1/2/2024   00:00.0  GBP   \n",
       "20  1/2/2024   14:32.0  GBP   \n",
       "\n",
       "                                                                           title  \n",
       "4   ANALYSIS-Sterling runs into economic and election hurdles after stellar year  \n",
       "6                             BUZZ-GBP/USD tentatively bid but signals are mixed  \n",
       "9      FOREX-Dollar starts2024 with gains on yen and euro, bitcoin above $45,000  \n",
       "15                                REG-VinaCapital Vietnam- Daily Net Asset Value  \n",
       "20                        BUZZ-Larger option expiries for Tuesday's New York cut  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deleted_by_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb865ae-d005-4a35-b089-0885fddf0919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Orignal DataFrame Rows: 22\n",
      "Orignal DataFrame Rows after min word number limit: 21\n",
      "Union DataFrame Rows: 21\n",
      "Three Methods Deleted DataFrame Rows: 1\n",
      "Union of Keyword and TF-IDF DataFrames Rows: 20\n",
      "Union of Keyword and LDA DataFrames Rows: 19\n",
      "Union of TF-IDF and LDA DataFrames Rows: 21\n",
      "Intersection between Keyword and TF-IDF DataFrames Rows: 16\n",
      "Intersection between Keyword and LDA DataFrames Rows: 14\n",
      "Intersection between TF-IDF and LDA DataFrames Rows: 14\n"
     ]
    }
   ],
   "source": [
    "# Calculate the overall union\n",
    "union_df = pd.concat([filtered_df_kw, filtered_df_tfidf, filtered_df_lda]).drop_duplicates()\n",
    "\n",
    "# Calculate the deleted results\n",
    "df_three_methods_deleted = df0[~df0.index.isin(union_df.index)]\n",
    "\n",
    "# Calculate the union and intersection between different filtered DataFrames\n",
    "union_kw_tfidf = pd.concat([filtered_df_kw, filtered_df_tfidf]).drop_duplicates()\n",
    "union_kw_lda = pd.concat([filtered_df_kw, filtered_df_lda]).drop_duplicates()\n",
    "union_tfidf_lda = pd.concat([filtered_df_tfidf, filtered_df_lda]).drop_duplicates()\n",
    "\n",
    "intersection_kw_tfidf = pd.merge(filtered_df_kw, filtered_df_tfidf, how='inner')\n",
    "intersection_kw_lda = pd.merge(filtered_df_kw, filtered_df_lda, how='inner')\n",
    "intersection_tfidf_lda = pd.merge(filtered_df_tfidf, filtered_df_lda, how='inner')\n",
    "\n",
    "# Store the overall union as CSV and Excel files\n",
    "union_df.to_csv('result/union_df.csv', index=False)\n",
    "union_df.to_excel('result/union_df.xlsx', index=False)\n",
    "\n",
    "# Store as CSV and Excel files\n",
    "df_three_methods_deleted.to_csv('result/df_three_methods_deleted.csv', index=False)\n",
    "df_three_methods_deleted.to_excel('result/df_three_methods_deleted.xlsx', index=False)\n",
    "\n",
    "union_kw_tfidf.to_csv('result/union_kw_tfidf.csv', index=False)\n",
    "union_kw_tfidf.to_excel('result/union_kw_tfidf.xlsx', index=False)\n",
    "union_kw_lda.to_csv('result/union_kw_lda.csv', index=False)\n",
    "union_kw_lda.to_excel('result/union_kw_lda.xlsx', index=False)\n",
    "union_tfidf_lda.to_csv('result/union_tfidf_lda.csv', index=False)\n",
    "union_tfidf_lda.to_excel('result/union_tfidf_lda.xlsx', index=False)\n",
    "intersection_kw_tfidf.to_csv('result/intersection_kw_tfidf.csv', index=False)\n",
    "intersection_kw_tfidf.to_excel('result/intersection_kw_tfidf.xlsx', index=False)\n",
    "intersection_kw_lda.to_csv('result/intersection_kw_lda.csv', index=False)\n",
    "intersection_kw_lda.to_excel('result/intersection_kw_lda.xlsx', index=False)\n",
    "intersection_tfidf_lda.to_csv('result/intersection_tfidf_lda.csv', index=False)\n",
    "intersection_tfidf_lda.to_excel('result/intersection_tfidf_lda.xlsx', index=False)\n",
    "\n",
    "# Final summary\n",
    "print(\"\\nSummary:\")\n",
    "print(\"Orignal DataFrame Rows:\", len(df0))\n",
    "print(\"Orignal DataFrame Rows after min word number limit:\", len(df))\n",
    "print(\"Union DataFrame Rows:\", len(union_df))\n",
    "print(\"Three Methods Deleted DataFrame Rows:\", len(df_three_methods_deleted))\n",
    "print(\"Union of Keyword and TF-IDF DataFrames Rows:\", len(union_kw_tfidf))\n",
    "print(\"Union of Keyword and LDA DataFrames Rows:\", len(union_kw_lda))\n",
    "print(\"Union of TF-IDF and LDA DataFrames Rows:\", len(union_tfidf_lda))\n",
    "print(\"Intersection between Keyword and TF-IDF DataFrames Rows:\", len(intersection_kw_tfidf))\n",
    "print(\"Intersection between Keyword and LDA DataFrames Rows:\", len(intersection_kw_lda))\n",
    "print(\"Intersection between TF-IDF and LDA DataFrames Rows:\", len(intersection_tfidf_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05287845-9456-4a56-8714-a8dcf8eabf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sym</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>56:48.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>U.S. FX Markets Open-January 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date timestamp  sym                           title\n",
       "13  1/2/2024   56:48.0  GBP  U.S. FX Markets Open-January 2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_three_methods_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76306364-5590-41eb-a9da-4bd65ed10231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254c971-3007-4880-89c7-c5c03f48138f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0007bc-8cab-4668-82e6-d354e956f86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a48fff-e7a9-4f80-a25c-297613e70c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tinyrag",
   "language": "python",
   "name": "tinyrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
